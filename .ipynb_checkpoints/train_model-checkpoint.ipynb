{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning Model is trained and report genereated in this Notebook**  \n",
    "   \n",
    "   \n",
    "   \n",
    "**Section 1:  Developing ML model for existing employees**  \n",
    "In this section, an ML model to predict the performance rating of **existing employees** or any employee not in the given data base is developed.  \n",
    "   \n",
    "   \n",
    "Following techniques are applied to get good accuracy.  \n",
    "1. Feature considered   :   \n",
    "List of top features obtained from file data_exploratory_analysis.ipynb, \"Section 2\".   \n",
    "Least important features are dropped to optimize the model for high accuracy   \n",
    "2. Encoding             :   \n",
    "Categorical columns are encoded using two techniques, 'Lable Encoding', 'One Hot Encoding' to figure out what encoding gives better accuracy   \n",
    "3. Data balancing       :   \n",
    "Most performance ratings are tagged as 3 and hence the model learns from imbalance data, 'smote' technique is used to balance the data.  \n",
    "4. Algorithms           :  \n",
    "Random Forest, XGBoost, Support Vector Machine and Artificial Neural Network algorithms are tried and their parameters are tuned   \n",
    "     \n",
    "      \n",
    "**Report 1:**  \n",
    "    All features considered, \n",
    "    Label Encoding done, \n",
    "    Data remains imbalance, \n",
    "    Random Forest Considered   \n",
    "\n",
    "Train Accuracy :  100.0(Accuracy with trained data)   \n",
    "**Test  Accuracy** :  92.5 \n",
    "\n",
    "-----------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           2       0.89      0.89      0.89        63\n",
    "           3       0.94      0.96      0.95       264\n",
    "           4       0.82      0.70      0.75        33\n",
    "           \n",
    "           \n",
    "**Report 2:**   \n",
    "    All features considered, \n",
    "    **One Hot Encoding** done, \n",
    "    Data remains imbalance, \n",
    "    Random Forest Considered   \n",
    "\n",
    "Train Accuracy :  100.0   \n",
    "**Test  Accuracy :  91.67**        \n",
    "\n",
    "-----------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           2       0.91      0.84      0.88        63\n",
    "           3       0.92      0.97      0.95       264\n",
    "           4       0.84      0.64      0.72        33\n",
    "  \n",
    "**Report 3:**   \n",
    "    All features considered,   \n",
    "    Label Encoding done,     \n",
    "    **Data balanced using smote**,         \n",
    "    Random Forest Considered      \n",
    "    \n",
    "Train Accuracy :  100.0     \n",
    "**Test  Accuracy :  93.06**     \n",
    "\n",
    "-----------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           2       0.90      0.89      0.90        63\n",
    "           3       0.95      0.96      0.96       264\n",
    "           4       0.79      0.79      0.79        33\n",
    "           \n",
    "           \n",
    "**Note 1:** Some less import features are dropped, but model did not see improvement any further.   \n",
    "**Note 2:** XGBoost algorithm and Support Vector Classifier algorithms were tried, did not see accuracy better than Random Forest algorithm.\n",
    "   \n",
    "     \n",
    "       \n",
    "      \n",
    "   \n",
    "    \n",
    "**Section 2:  Developing ML model for new hire**\n",
    "\n",
    "In this section, an ML model to predict the performance rating of a new hire is developed.   \n",
    "At the time of new hire selection process we will not have all the features provided in the data.    \n",
    "We need to select only those features that are available at the time of hiring.  \n",
    "\n",
    "Addition to accuracy improvement techninques applied in Section 1, following technique/algorithms/ideas considered in this section.\n",
    " \n",
    "1. Judiciously classify the features as those that are available at hiring and those that are not available.   \n",
    "Some features can be easily classfied by intuition, for others data analysis is essential.    \n",
    "Analysis of this classification is in \"Section 2\" of file data_processing.ipynb.   \n",
    "Following features will be used   \n",
    "    'Age',  \n",
    "    'Gender',  \n",
    "    'EducationBackground',  \n",
    "    'MaritalStatus',  \n",
    "    'EmpDepartment',  \n",
    "    'EmpJobRole',  \n",
    "    'BusinessTravelFrequency',  \n",
    "    'DistanceFromHome',  \n",
    "    'EmpEducationLevel',  \n",
    "    'EmpHourlyRate',  \n",
    "    'EmpJobLevel',  \n",
    "    'NumCompaniesWorked',  \n",
    "    'EmpLastSalaryHikePercent',  \n",
    "    'TotalWorkExperienceInYears',    \n",
    "    \n",
    "2. Addition to Random Forest and XGBoost, other algorithms like Support Vector Machine/Classifier, Artifical Neural Nerwork are considered  \n",
    "   \n",
    "   \n",
    "Each of these algorithms have been tried   \n",
    "* with their default parameters,   \n",
    "* later with balanced data and   \n",
    "* again with best tuned parameter.      \n",
    "\n",
    "Since the target data is imbalanced, accuracy alone doesn't explain how good or bad a model is.  \n",
    "Statistical recall also matters.   \n",
    "Based on accuracy and recall, I recommend XGBoost algorithm, trained with balanced data with following hyper parameters.   \n",
    "\n",
    "'colsample_bylevel': 0.8,  \n",
    " 'colsample_bytree': 0.8,  \n",
    " 'learning_rate': 0.4,  \n",
    " 'max_depth': 8,  \n",
    " 'min_child_weight': 2,  \n",
    " 'n_estimators': 100,  \n",
    " 'subsample': 0.9  \n",
    " \n",
    " \n",
    "**Report for the selected model :**   \n",
    "\n",
    " \n",
    "Train Accuracy :  86.03   \n",
    "**Test  Accuracy :  64.72**\n",
    "\n",
    " \n",
    "-----------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           2       0.21      0.22      0.21        63\n",
    "           3       0.80      0.73      0.77       264\n",
    "           4       0.50      0.76      0.60        33\n",
    "\n",
    "    accuracy                           0.65       360\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Employee_Data.xls', index_col='EmpNumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EducationBackground</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>EmpDepartment</th>\n",
       "      <th>EmpJobRole</th>\n",
       "      <th>BusinessTravelFrequency</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>EmpEducationLevel</th>\n",
       "      <th>EmpEnvironmentSatisfaction</th>\n",
       "      <th>...</th>\n",
       "      <th>EmpRelationshipSatisfaction</th>\n",
       "      <th>TotalWorkExperienceInYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>EmpWorkLifeBalance</th>\n",
       "      <th>ExperienceYearsAtThisCompany</th>\n",
       "      <th>ExperienceYearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>PerformanceRating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EmpNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E1001000</th>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Single</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Sales Executive</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E1001006</th>\n",
       "      <td>47</td>\n",
       "      <td>Male</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Single</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Sales Executive</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age Gender EducationBackground MaritalStatus EmpDepartment  \\\n",
       "EmpNumber                                                               \n",
       "E1001000    32   Male           Marketing        Single         Sales   \n",
       "E1001006    47   Male           Marketing        Single         Sales   \n",
       "\n",
       "                EmpJobRole BusinessTravelFrequency  DistanceFromHome  \\\n",
       "EmpNumber                                                              \n",
       "E1001000   Sales Executive           Travel_Rarely                10   \n",
       "E1001006   Sales Executive           Travel_Rarely                14   \n",
       "\n",
       "           EmpEducationLevel  EmpEnvironmentSatisfaction  ...  \\\n",
       "EmpNumber                                                 ...   \n",
       "E1001000                   3                           4  ...   \n",
       "E1001006                   4                           4  ...   \n",
       "\n",
       "           EmpRelationshipSatisfaction  TotalWorkExperienceInYears  \\\n",
       "EmpNumber                                                            \n",
       "E1001000                             4                          10   \n",
       "E1001006                             4                          20   \n",
       "\n",
       "           TrainingTimesLastYear  EmpWorkLifeBalance  \\\n",
       "EmpNumber                                              \n",
       "E1001000                       2                   2   \n",
       "E1001006                       2                   3   \n",
       "\n",
       "           ExperienceYearsAtThisCompany ExperienceYearsInCurrentRole  \\\n",
       "EmpNumber                                                              \n",
       "E1001000                             10                            7   \n",
       "E1001006                              7                            7   \n",
       "\n",
       "           YearsSinceLastPromotion  YearsWithCurrManager  Attrition  \\\n",
       "EmpNumber                                                             \n",
       "E1001000                         0                     8         No   \n",
       "E1001006                         1                     7         No   \n",
       "\n",
       "           PerformanceRating  \n",
       "EmpNumber                     \n",
       "E1001000                   3  \n",
       "E1001006                   3  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the data, Features that contain only labels(categorical label) are\n",
    "cat_columns = ['Gender', 'EducationBackground', 'MaritalStatus','EmpDepartment', 'EmpJobRole', 'BusinessTravelFrequency', \n",
    "               'Attrition', 'OverTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the data, Features that contain only numerical Discrete values are\n",
    "num_columns = ['Age', 'DistanceFromHome', 'EmpEducationLevel', 'EmpEnvironmentSatisfaction','EmpHourlyRate', \n",
    "               'EmpJobInvolvement', 'EmpJobLevel', 'EmpJobSatisfaction', 'NumCompaniesWorked', 'EmpLastSalaryHikePercent', \n",
    "               'EmpRelationshipSatisfaction','TotalWorkExperienceInYears', 'TrainingTimesLastYear', 'EmpWorkLifeBalance', \n",
    "               'ExperienceYearsAtThisCompany','ExperienceYearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "               'YearsWithCurrManager', 'PerformanceRating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility Function\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "def predict_n_print_report(model, X_train, X_test, y_train, y_test):\n",
    "    y_predict = model.predict(X_test)\n",
    "    y_train_predict = model.predict(X_train)\n",
    "    \n",
    "    print('Train Accuracy : ', accuracy_score(y_train, y_train_predict).round(4)*100)\n",
    "    print('Test  Accuracy : ', accuracy_score(y_test,  y_predict).round(4)*100)\n",
    "    print('-----------------------------------------------------')\n",
    "    print(pd.crosstab(y_test, y_predict, rownames=['Actual '+y_test.name], colnames=['Predicted']))\n",
    "    print('-----------------------------------------------------')\n",
    "    print( classification_report(y_test,y_predict) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## section 1: Predict the performance of Existing employees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML model to predict the performance rating of Existing employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('PerformanceRating', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.PerformanceRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encode categorical-label columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "for labelColumn in cat_columns:\n",
    "    X[labelColumn] = enc.fit_transform(X[labelColumn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EducationBackground</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>EmpDepartment</th>\n",
       "      <th>EmpJobRole</th>\n",
       "      <th>BusinessTravelFrequency</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>EmpEducationLevel</th>\n",
       "      <th>EmpEnvironmentSatisfaction</th>\n",
       "      <th>...</th>\n",
       "      <th>EmpLastSalaryHikePercent</th>\n",
       "      <th>EmpRelationshipSatisfaction</th>\n",
       "      <th>TotalWorkExperienceInYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>EmpWorkLifeBalance</th>\n",
       "      <th>ExperienceYearsAtThisCompany</th>\n",
       "      <th>ExperienceYearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <th>Attrition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EmpNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E1001000</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E1001006</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age  Gender  EducationBackground  MaritalStatus  EmpDepartment  \\\n",
       "EmpNumber                                                                   \n",
       "E1001000    32       1                    2              2              5   \n",
       "E1001006    47       1                    2              2              5   \n",
       "\n",
       "           EmpJobRole  BusinessTravelFrequency  DistanceFromHome  \\\n",
       "EmpNumber                                                          \n",
       "E1001000           13                        2                10   \n",
       "E1001006           13                        2                14   \n",
       "\n",
       "           EmpEducationLevel  EmpEnvironmentSatisfaction  ...  \\\n",
       "EmpNumber                                                 ...   \n",
       "E1001000                   3                           4  ...   \n",
       "E1001006                   4                           4  ...   \n",
       "\n",
       "           EmpLastSalaryHikePercent  EmpRelationshipSatisfaction  \\\n",
       "EmpNumber                                                          \n",
       "E1001000                         12                            4   \n",
       "E1001006                         12                            4   \n",
       "\n",
       "           TotalWorkExperienceInYears  TrainingTimesLastYear  \\\n",
       "EmpNumber                                                      \n",
       "E1001000                           10                      2   \n",
       "E1001006                           20                      2   \n",
       "\n",
       "           EmpWorkLifeBalance  ExperienceYearsAtThisCompany  \\\n",
       "EmpNumber                                                     \n",
       "E1001000                    2                            10   \n",
       "E1001006                    3                             7   \n",
       "\n",
       "           ExperienceYearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "EmpNumber                                                          \n",
       "E1001000                              7                        0   \n",
       "E1001006                              7                        1   \n",
       "\n",
       "           YearsWithCurrManager  Attrition  \n",
       "EmpNumber                                   \n",
       "E1001000                      8          0  \n",
       "E1001006                      7          0  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoding\n",
    "X = pd.get_dummies(X, columns=cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=10, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train (840, 61)\n",
      "Shape of X_test (360, 61)\n",
      "Shape of y_train (840,)\n",
      "Shape of y_test (360,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train', X_train.shape)\n",
    "print('Shape of X_test', X_test.shape)\n",
    "print('Shape of y_train', y_train.shape)\n",
    "print('Shape of y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y train data imbalance :  Counter({3: 610, 2: 131, 4: 99})\n",
      "Y test  data imbalance :  Counter({3: 264, 2: 63, 4: 33})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print('Y train data imbalance : ', Counter(y_train))\n",
    "print('Y test  data imbalance : ', Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE({2: 500, 3: 610, 4: 400})\n",
    "X_train_smote, y_train_smote = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "X_train = pd.DataFrame(X_train_smote, columns=X_test.columns)\n",
    "\n",
    "y_train = pd.Series(y_train_smote, name=y_train.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelrf = RandomForestClassifier(random_state=0) \n",
    "\n",
    "modelrf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  100.0\n",
      "Test  Accuracy :  91.94\n",
      "-----------------------------------------------------\n",
      "Predicted                  2    3   4\n",
      "Actual PerformanceRating             \n",
      "2                         55    8   0\n",
      "3                          4  253   7\n",
      "4                          3    7  23\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.89      0.87      0.88        63\n",
      "           3       0.94      0.96      0.95       264\n",
      "           4       0.77      0.70      0.73        33\n",
      "\n",
      "    accuracy                           0.92       360\n",
      "   macro avg       0.87      0.84      0.85       360\n",
      "weighted avg       0.92      0.92      0.92       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_n_print_report(modelrf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: ML model for new hire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Considering only those features that are available for new employee hiring, Some features like 'Age' are obviously available at the time of hiring, but other fetures like 'EmpLastSalaryHikePercent' or  'OverTime' are not that obvious. Analysis of not so obvious features are in jupyter notebook \"Section 2\" of  **IABAC_Project_Submission/src/Data_Processing/data_processing.ipynb**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From IABAC_Project_Submission/src/Data_Processing/data_processing.ipynb\n",
    "new_hire_columns = ['Age',\n",
    " 'Gender',\n",
    " 'EducationBackground',\n",
    " 'MaritalStatus',\n",
    " 'EmpDepartment',\n",
    " 'EmpJobRole',\n",
    " 'BusinessTravelFrequency',\n",
    " 'DistanceFromHome',\n",
    " 'EmpEducationLevel',\n",
    " #'EmpEnvironmentSatisfaction',\n",
    " 'EmpHourlyRate',\n",
    " #'EmpJobInvolvement',\n",
    " 'EmpJobLevel',\n",
    " #'EmpJobSatisfaction',\n",
    " 'NumCompaniesWorked',\n",
    " #'OverTime',\n",
    " 'EmpLastSalaryHikePercent',\n",
    " #'EmpRelationshipSatisfaction',\n",
    " 'TotalWorkExperienceInYears',\n",
    " #'TrainingTimesLastYear',\n",
    " #'EmpWorkLifeBalance',\n",
    " #'ExperienceYearsAtThisCompany',\n",
    " #'ExperienceYearsInCurrentRole',\n",
    " #'YearsSinceLastPromotion',\n",
    " #'YearsWithCurrManager',\n",
    " #'Attrition',\n",
    " #'PerformanceRating'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[new_hire_columns] # X represents data frame containing data for new hire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Label Encode categorical-label columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "for labelColumn in cat_columns:\n",
    "    if labelColumn in new_hire_columns:\n",
    "        X[labelColumn] = enc.fit_transform(X[labelColumn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.PerformanceRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=10, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1: Random Forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelrf = RandomForestClassifier(n_estimators=100, random_state=0) \n",
    "modelrf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Gender', 'EducationBackground', 'MaritalStatus',\n",
       "       'EmpDepartment', 'EmpJobRole', 'BusinessTravelFrequency',\n",
       "       'DistanceFromHome', 'EmpEducationLevel', 'EmpHourlyRate', 'EmpJobLevel',\n",
       "       'NumCompaniesWorked', 'EmpLastSalaryHikePercent',\n",
       "       'TotalWorkExperienceInYears'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  100.0\n",
      "Test  Accuracy :  77.22\n",
      "-----------------------------------------------------\n",
      "Predicted                 2    3   4\n",
      "Actual PerformanceRating            \n",
      "2                         4   54   5\n",
      "3                         2  250  12\n",
      "4                         1    8  24\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.57      0.06      0.11        63\n",
      "           3       0.80      0.95      0.87       264\n",
      "           4       0.59      0.73      0.65        33\n",
      "\n",
      "    accuracy                           0.77       360\n",
      "   macro avg       0.65      0.58      0.54       360\n",
      "weighted avg       0.74      0.77      0.72       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_n_print_report(modelrf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 131, 3: 610, 4: 99})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note :**  \n",
    "The data is very imbalanced. \n",
    "Accuracy is No. of correct predictions / Total number of observations. In the above case 278/360 = 77.22%  \n",
    "Here, even if we predict everything as 3, 264/360 = 73.33%\n",
    "So, we are not happy with the accuracy of 77.22%. Also, the recall is only 0.06 for rating=2, this is a concern.  \n",
    "Hence lets train the model with balanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting using Balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE({2: 500, 3: 610, 4: 400})\n",
    "X_train_smote, y_train_smote = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "X_train = pd.DataFrame(X_train_smote, columns=X_test.columns)\n",
    "\n",
    "y_train = pd.Series(y_train_smote, name=y_train.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelrf_smote = RandomForestClassifier(n_estimators=50, random_state=0) \n",
    "modelrf_smote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  78.61\n",
      "Test  Accuracy :  77.22\n",
      "-----------------------------------------------------\n",
      "Predicted                 2    3   4\n",
      "Actual PerformanceRating            \n",
      "2                         4   54   5\n",
      "3                         2  250  12\n",
      "4                         1    8  24\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.57      0.06      0.11        63\n",
      "           3       0.80      0.95      0.87       264\n",
      "           4       0.59      0.73      0.65        33\n",
      "\n",
      "    accuracy                           0.77       360\n",
      "   macro avg       0.65      0.58      0.54       360\n",
      "weighted avg       0.74      0.77      0.72       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_n_print_report(modelrf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GridSearch to tune Random Forest parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=8, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=0,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'criterion': ['gini', 'entropy'],\n",
       "                          'min_samples_leaf': [1, 2, 3],\n",
       "                          'min_samples_split': [2, 3, 4, 5],\n",
       "                          'n_estimators': [20, 50, 100]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params=[{\n",
    "    'n_estimators':[20, 50, 100],\n",
    "    'min_samples_split':[2,3,4,5],\n",
    "    'criterion':['gini','entropy'],\n",
    "    'min_samples_leaf':[1,2,3]\n",
    "}]\n",
    "\n",
    "modelrf_gs=GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=0), \n",
    "    param_grid=params, \n",
    "    #scoring='accuracy',\n",
    "    cv=8)\n",
    "modelrf_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelrf_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  100.0\n",
      "Test  Accuracy :  69.72\n",
      "-----------------------------------------------------\n",
      "Predicted                  2    3   4\n",
      "Actual PerformanceRating             \n",
      "2                         16   41   6\n",
      "3                         40  209  15\n",
      "4                          2    5  26\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.28      0.25      0.26        63\n",
      "           3       0.82      0.79      0.81       264\n",
      "           4       0.55      0.79      0.65        33\n",
      "\n",
      "    accuracy                           0.70       360\n",
      "   macro avg       0.55      0.61      0.57       360\n",
      "weighted avg       0.70      0.70      0.70       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_n_print_report(modelrf_gs, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note :**  \n",
    "Here, the data is relatively balanced.   \n",
    "Used GridSearch tool to decide on algorithm parameter.  \n",
    "Although accuracy is not as good as previous models, the recall for performance rating=2 is much better.  \n",
    "So, recommending this model to use to filter new hires.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 2: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[new_hire_columns] # X represents data frame containing data for new hire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Label Encode categorical-label columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "for labelColumn in cat_columns:\n",
    "    if labelColumn in new_hire_columns:\n",
    "        X[labelColumn] = enc.fit_transform(X[labelColumn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.PerformanceRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=10, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "modelxg = XGBClassifier(random_state=0)\n",
    "modelxg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  85.0\n",
      "Test  Accuracy :  77.78\n",
      "-----------------------------------------------------\n",
      "Predicted                 2    3   4\n",
      "Actual PerformanceRating            \n",
      "2                         4   51   8\n",
      "3                         1  252  11\n",
      "4                         1    8  24\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.67      0.06      0.12        63\n",
      "           3       0.81      0.95      0.88       264\n",
      "           4       0.56      0.73      0.63        33\n",
      "\n",
      "    accuracy                           0.78       360\n",
      "   macro avg       0.68      0.58      0.54       360\n",
      "weighted avg       0.76      0.78      0.72       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_n_print_report(modelxg, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE({2: 500, 3: 610, 4: 400})\n",
    "X_train_smote, y_train_smote = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "X_train = pd.DataFrame(X_train_smote, columns=X_test.columns)\n",
    "\n",
    "y_train = pd.Series(y_train_smote, name=y_train.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelxg_smote = XGBClassifier(random_state=0)\n",
    "modelxg_smote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  86.49\n",
      "Test  Accuracy :  63.33\n",
      "-----------------------------------------------------\n",
      "Predicted                  2    3   4\n",
      "Actual PerformanceRating             \n",
      "2                         14   40   9\n",
      "3                         59  188  17\n",
      "4                          1    6  26\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.19      0.22      0.20        63\n",
      "           3       0.80      0.71      0.76       264\n",
      "           4       0.50      0.79      0.61        33\n",
      "\n",
      "    accuracy                           0.63       360\n",
      "   macro avg       0.50      0.57      0.52       360\n",
      "weighted avg       0.67      0.63      0.65       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_n_print_report(modelxg_smote, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning XGBoost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=8, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'learning_rate': [0.05, 0.1, 0.4],\n",
       "                          'max_depth': [2, 3, 6],\n",
       "                          'min_child_weight': [2, 5, 10],\n",
       "                          'subsample': [0.8, 0.9, 1]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params=[{\n",
    "    'learning_rate':[0.05, 0.1, 0.4], \n",
    "    'max_depth':[2,3,6], \n",
    "    'min_child_weight':[2,5,10], \n",
    "    'subsample':[0.8,0.9,1],\n",
    "    #'colsample_bytree':0.8,\n",
    "    #'colsample_bylevel':1,\n",
    "    #'n_estimators':100,\n",
    "    #'gamma':0,\n",
    "    #'reg_alpha':0, \n",
    "    #'reg_lambda':1,\n",
    "    }]\n",
    "\n",
    "modelxg_gs=GridSearchCV(\n",
    "    estimator=XGBClassifier(random_state=0), \n",
    "    param_grid=params, \n",
    "    cv=8)\n",
    "modelxg_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.4, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.8}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelxg_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  86.49\n",
      "Test  Accuracy :  63.33\n",
      "-----------------------------------------------------\n",
      "Predicted                  2    3   4\n",
      "Actual PerformanceRating             \n",
      "2                         14   40   9\n",
      "3                         59  188  17\n",
      "4                          1    6  26\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.19      0.22      0.20        63\n",
      "           3       0.80      0.71      0.76       264\n",
      "           4       0.50      0.79      0.61        33\n",
      "\n",
      "    accuracy                           0.63       360\n",
      "   macro avg       0.50      0.57      0.52       360\n",
      "weighted avg       0.67      0.63      0.65       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_n_print_report(modelxg_smote, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning more XGBoost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=8, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_po...t=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'colsample_bylevel': [0.8, 0.9, 1],\n",
       "                          'colsample_bytree': [0.8, 0.9, 1],\n",
       "                          'learning_rate': [0.4], 'max_depth': [6, 8],\n",
       "                          'min_child_weight': [2],\n",
       "                          'n_estimators': [50, 100, 150], 'subsample': [0.9]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params=[{\n",
    "    'learning_rate':[0.4], \n",
    "    'max_depth':[6,8], \n",
    "    'min_child_weight':[2], \n",
    "    'subsample':[0.9],\n",
    "    'colsample_bytree':[0.8,0.9,1],\n",
    "    'colsample_bylevel':[0.8,0.9,1],\n",
    "    'n_estimators':[50,100,150],\n",
    "    #'gamma':0,\n",
    "    #'reg_alpha':[0,0.1], \n",
    "    #'reg_lambda':[1, 1.1],\n",
    "    }]\n",
    "\n",
    "modelxg_gs=GridSearchCV(\n",
    "    estimator=XGBClassifier(random_state=0), \n",
    "    param_grid=params, \n",
    "    cv=8)\n",
    "modelxg_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bylevel': 0.8,\n",
       " 'colsample_bytree': 0.9,\n",
       " 'learning_rate': 0.4,\n",
       " 'max_depth': 8,\n",
       " 'min_child_weight': 2,\n",
       " 'n_estimators': 100,\n",
       " 'subsample': 0.9}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelxg_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  86.49\n",
      "Test  Accuracy :  63.33\n",
      "-----------------------------------------------------\n",
      "Predicted                  2    3   4\n",
      "Actual PerformanceRating             \n",
      "2                         14   40   9\n",
      "3                         59  188  17\n",
      "4                          1    6  26\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.19      0.22      0.20        63\n",
      "           3       0.80      0.71      0.76       264\n",
      "           4       0.50      0.79      0.61        33\n",
      "\n",
      "    accuracy                           0.63       360\n",
      "   macro avg       0.50      0.57      0.52       360\n",
      "weighted avg       0.67      0.63      0.65       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_n_print_report(modelxg_smote, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 3: Support Vector Machine/Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[new_hire_columns] # X represents data frame containing data for new hire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Label Encode categorical-label columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "for labelColumn in cat_columns:\n",
    "    if labelColumn in new_hire_columns:\n",
    "        X[labelColumn] = enc.fit_transform(X[labelColumn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.PerformanceRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=10, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=10, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model_svm = SVC(\n",
    "    #C=200, \n",
    "    #gamma=0.08, \n",
    "    random_state=10)  # C between 0.1 to 1000(helps in mainting margin), gamma - 0.01 to 10(for smoothening curve)\n",
    "model_svm.fit(X_train,y_train) # training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  72.61999999999999\n",
      "Test  Accuracy :  73.33\n",
      "-----------------------------------------------------\n",
      "Predicted                   3\n",
      "Actual PerformanceRating     \n",
      "2                          63\n",
      "3                         264\n",
      "4                          33\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00        63\n",
      "           3       0.73      1.00      0.85       264\n",
      "           4       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.73       360\n",
      "   macro avg       0.24      0.33      0.28       360\n",
      "weighted avg       0.54      0.73      0.62       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predict_n_print_report(model_svm, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note :**  \n",
    "By using default params, SVM has provided very bad prediction. It would predict every new hire would have performance rating equal to 3.    \n",
    "By balancing the data, we will have better prediction  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE({2: 500, 3: 610, 4: 400})\n",
    "X_train_smote, y_train_smote = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "X_train = pd.DataFrame(X_train_smote, columns=X_test.columns)\n",
    "\n",
    "y_train = pd.Series(y_train_smote, name=y_train.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=10, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm_smote = SVC(\n",
    "    #C=100, \n",
    "    #gamma=0.08, \n",
    "    random_state=10)  # C between 0.1 to 1000(helps in mainting margin), gamma - 0.01 to 10(for smoothening curve)\n",
    "model_svm_smote.fit(X_train,y_train) # training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  64.3\n",
      "Test  Accuracy :  62.22\n",
      "-----------------------------------------------------\n",
      "Predicted                  2    3   4\n",
      "Actual PerformanceRating             \n",
      "2                         11   39  13\n",
      "3                         49  185  30\n",
      "4                          2    3  28\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.18      0.17      0.18        63\n",
      "           3       0.81      0.70      0.75       264\n",
      "           4       0.39      0.85      0.54        33\n",
      "\n",
      "    accuracy                           0.62       360\n",
      "   macro avg       0.46      0.57      0.49       360\n",
      "weighted avg       0.66      0.62      0.63       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_n_print_report(model_svm_smote, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning SVM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=8, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=10, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'C': [0.1, 1, 10, 100, 500],\n",
       "                          'gamma': [0.05, 0.5, 5]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params=[{\n",
    "    'C':[0.1,1,10,100,500], \n",
    "    'gamma':[0.05, 0.5, 5],\n",
    "}]\n",
    "\n",
    "modelsvm_gs=GridSearchCV(\n",
    "    estimator=SVC(random_state=10), \n",
    "    param_grid=params, \n",
    "    cv=8)\n",
    "modelsvm_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.05}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelsvm_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  100.0\n",
      "Test  Accuracy :  71.94\n",
      "-----------------------------------------------------\n",
      "Predicted                 2    3  4\n",
      "Actual PerformanceRating           \n",
      "2                         1   62  0\n",
      "3                         5  257  2\n",
      "4                         0   32  1\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.17      0.02      0.03        63\n",
      "           3       0.73      0.97      0.84       264\n",
      "           4       0.33      0.03      0.06        33\n",
      "\n",
      "    accuracy                           0.72       360\n",
      "   macro avg       0.41      0.34      0.31       360\n",
      "weighted avg       0.60      0.72      0.62       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_n_print_report(modelsvm_gs, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 4: Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[new_hire_columns] # X represents data frame containing data for new hire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Label Encode categorical-label columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "for labelColumn in cat_columns:\n",
    "    if labelColumn in new_hire_columns:\n",
    "        X[labelColumn] = enc.fit_transform(X[labelColumn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.PerformanceRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "X_ANN = scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_ANN,\n",
    "    y,\n",
    "random_state=10, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(90, 90, 90), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=10, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier # Multi layer percetron classifier\n",
    "model_ann = MLPClassifier(hidden_layer_sizes=(90,90,90), random_state=10)\n",
    "model_ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  100.0\n",
      "Test  Accuracy :  69.44\n",
      "-----------------------------------------------------\n",
      "Predicted                  2    3   4\n",
      "Actual PerformanceRating             \n",
      "2                         16   44   3\n",
      "3                         35  219  10\n",
      "4                          3   15  15\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.30      0.25      0.27        63\n",
      "           3       0.79      0.83      0.81       264\n",
      "           4       0.54      0.45      0.49        33\n",
      "\n",
      "    accuracy                           0.69       360\n",
      "   macro avg       0.54      0.51      0.52       360\n",
      "weighted avg       0.68      0.69      0.69       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_n_print_report(model_ann, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN with balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\91984\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE({2: 500, 3: 610, 4: 400})\n",
    "X_train_smote, y_train_smote = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "X_train = pd.DataFrame(X_train_smote, columns=X.columns)\n",
    "\n",
    "y_train = pd.Series(y_train_smote, name=y.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(90, 90, 90), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=10, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier # Multi layer percetron classifier\n",
    "model_ann = MLPClassifier(hidden_layer_sizes=(90,90,90), random_state=10)\n",
    "model_ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  100.0\n",
      "Test  Accuracy :  67.5\n",
      "-----------------------------------------------------\n",
      "Predicted                  2    3   4\n",
      "Actual PerformanceRating             \n",
      "2                         16   41   6\n",
      "3                         40  210  14\n",
      "4                          5   11  17\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.26      0.25      0.26        63\n",
      "           3       0.80      0.80      0.80       264\n",
      "           4       0.46      0.52      0.49        33\n",
      "\n",
      "    accuracy                           0.68       360\n",
      "   macro avg       0.51      0.52      0.51       360\n",
      "weighted avg       0.68      0.68      0.68       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_n_print_report(model_ann, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
